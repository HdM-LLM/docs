[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SkillSync",
    "section": "",
    "text": "Overview\nThis documentation is for the SkillSync application and covers the following topics:\n\nIntroduction: This section provides information about the purpose, scope, and objectives of the application.\nUse Case: This section provides a detailed description of the application’s use case.\nDesign Decisions: This section provides information about the design decisions made during the development of the application.\nImplementation: This section provides information about the implementation of the application.\nEvaluation: This section provides information about the evaluation of the application.\nUser Instructions: This section provides information about how to use the application.\nFuture Road Map: This section provides information about the future development of the application.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "In today’s competitive job market, recruiters are faced with the daunting task of sifting through countless resumes to find the perfect candidate for a given position. Traditional methods of resume screening often rely on manual review processes, which can be time-consuming, subjective, and prone to bias. One of the significant challenges in the recruitment process is the need for recruiters to possess expertise across various job fields to accurately assess the qualifications of applicants. However, it’s impractical for recruiters to be experts in every domain they’re hiring for, leading to potential gaps in understanding and evaluation.\nTo address these challenges, we have developed an innovative application called SkillSync, which aims to revolutionize the recruitment industry by harnessing the power of artificial intelligence (AI). Leveraging OpenAI’s GPT-4 model, our application offers recruiters a useful tool for analyzing applicant resumes and identifying the most qualified candidates for a given job.\nOur goal was to create a user-friendly, AI-powered recruitment tool that can help recruiters quickly and accurately evaluate resumes and identify the most qualified candidates. By automating the resume screening process, our application aims to save recruiters time and effort, reduce the potential for bias, and improve the overall efficiency of the recruitment process.\nIn this documentation, we will outline the process of creating this AI-powered recruitment tool, detailing the steps involved in deciding on the use case, designing the solution, and implementing the application. We will also provide information about how we evaluated the model’s performance and discuss potential future improvements.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "use_case.html",
    "href": "use_case.html",
    "title": "2  Use Case",
    "section": "",
    "text": "2.1 Use Case 1: AI Resume Rating\nOur main use case is to let AI rate an applicants’ resume. The applicant can upload his CV (in PDF format) and the AI will rate the resume based on the vacancy the user applies for. Each vacancy has a set of skills on which the resume will be rated. Each skill has a weight and guidelines for when to rate the skill with zero or ten points. The AI will rate the resume which results in a score which will be display in the user interface. The score will only be visible to the recruiter and not to the applicant. The recruiter can then decide if he wants to proceed with the applicant and invite him for an interview or reject the application. He could also contact the applicant to request additional information or to clarify some points.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Use Case</span>"
    ]
  },
  {
    "objectID": "use_case.html#use-case-2-ai-job-posting",
    "href": "use_case.html#use-case-2-ai-job-posting",
    "title": "2  Use Case",
    "section": "2.2 Use Case 2: AI Job Posting",
    "text": "2.2 Use Case 2: AI Job Posting\nThe second use case is to create a new job posting or vacancy with the help of AI. The recruiter only needs to enter the job title, a description of the job, and the required skills. The AI will then create a job posting based on the input of the recruiter. This vacancy is then displayed within our system among the other vacancies. Now, the recruiter can start receiving applications for the job. The AI will then rate the resumes of the applicants based on the vacancy and the recruiter can decide if the applicant is suitable for the job based on the score.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Use Case</span>"
    ]
  },
  {
    "objectID": "design_decisions.html",
    "href": "design_decisions.html",
    "title": "3  Design Decisions",
    "section": "",
    "text": "3.1 Vector Store\nAt the beginning of the project, we decided to use a vector store to store the information about the job vacancies and the applications. We thought that this would be a good way to store the information and to be able to retrieve it quickly. But during the implementation of the application, we realized that the vector store was not the best option for our use case which is why we decided to switch to a relational database. This decision was made because we realized that the relational database would be easier to use and would allow us to store the information in a more structured way. Additionally, we needed to store and retrieve whole documents and the vector store was not the best option for this either. For this purpose, we decided to use a document database.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design Decisions</span>"
    ]
  },
  {
    "objectID": "design_decisions.html#prompting",
    "href": "design_decisions.html#prompting",
    "title": "3  Design Decisions",
    "section": "3.2 Prompting",
    "text": "3.2 Prompting\n\n3.2.1 OpenAI API Integration and GPT Settings\nThe application utilizes OpenAI’s API, specifically the gpt-4-1106-preview model, to facilitate various tasks such as rating analysis, job vacancy creation, CV evaluation, and skill assessment. The integration of OpenAI’s API is central to the application’s functionality, with tailored GPT settings enhancing the utility and accuracy of AI-generated content. These settings are meticulously calibrated to align the AI’s output with the application’s quality standards and operational requirements, ensuring the generation of accurate, relevant, and useful content.\n\n3.2.1.1 Tailored GPT Settings for Enhanced Accuracy\n\nLow Temperature for Predictability A pivotal adjustment in the GPT settings is the use of a low temperature parameter, critical for minimizing the AI’s inclination towards creativity and significantly reducing the risk of generating hallucinated or irrelevant content.\nContextual Role Setting Through System Messages System messages define the context within which the GPT model operates, specifying roles such as a “critical Human Resources professional” to guide the model in tailoring its responses. This role-based prompting helps in generating content that is not only relevant but also specifically tailored to the application’s use case, ensuring the tone and substance of the AI’s output accurately reflect its assigned role.\n\n\n\n\n3.2.2 Advanced Prompting Techniques in Application Design\nWe’ve molded our application’s design around OpenAI’s best practices for prompt engineering, strategically advancing our AI content generation capabilities. These best practices guide the development of our prompts, ensuring they are effectively structured to elicit the desired AI responses.\n\n3.2.2.1 Prompt Engineering Principles\n\nClear and Structured Input: Each prompt is designed to be clear and direct, structured to elicit specific types of responses, ensuring standardized data handling and consistency across functionalities.\nGuided Responses with Context: Detailed guidelines and templates provide context, guiding the AI towards generating the desired output for tasks such as rating analysis and job vacancy creation.\nDecomposing Complex Tasks: Complex tasks are broken down into simpler components, improving model accuracy and manageability, mirroring best practices in software engineering.\nIncorporating Feedback Loops: The design includes feedback loops for iterative refinement based on the AI’s performance, enabling continuous improvement in content quality and relevance.\nDynamic Prompt Adjustments: Prompts are dynamically adjusted based on the task, optimizing the AI’s understanding and output accuracy through conditional prompting.\nSystematic Testing: A rigorous approach to testing evaluates and enhances the performance of the AI’s responses, ensuring modifications improve the overall quality and reliability.\nUse of Anchoring and Constraints: Clear boundaries and expectations are set for the AI’s responses, guiding the AI towards generating structured, focused outputs and minimizing the risk of off-topic responses.\n\nThis strategic use of prompt engineering principles, inspired by OpenAI’s guidelines, ensures our application’s interactions with the gpt-4-1106-preview model are both effective and efficient, maximizing the utility and quality of AI-generated content.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design Decisions</span>"
    ]
  },
  {
    "objectID": "implementation.html",
    "href": "implementation.html",
    "title": "4  Implementation",
    "section": "",
    "text": "4.1 Frontend",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "implementation.html#frontend",
    "href": "implementation.html#frontend",
    "title": "4  Implementation",
    "section": "",
    "text": "4.1.1 Design\nFor the frontend design, we first created a mockup with Figma to get a better idea of what we wanted the website to look like. When you open the website, you will see a dashboard, that gives you a great overview over everything an human resources employee needs to know. You can see how many job postings are open, how many applications you have received and how many people you have hired over the last 30 days.\n\n\n\nDashboard view\n\n\nAfter clicking on the ‘Vacancies’ button on the left side, you will see an overview over all open job postings. You can see the job title, the department and since when this job posting is online. You can also see the first few words of the job description.\n\n\n\nOverview over all open job postings\n\n\nIf you then wish to see who has applied to a specific job posting, you can simply click the job posting itself and you will see an overview over all applications. You can see the name of the applicant, the date of when the application was received and their rating based on the required skill set for the position they applied to.\n\n\n\nOverview over all applications for a specific job posting\n\n\nFor further information about the applicant and their rating, you can click on the ‘Details’ button and you will see a detailed overview over the applicant. You can see their name, their email address, their phone number, their address and their rating based on the required skill set for the position they applied to with a justification and a original quote from their cv. You also have the option via the buttons on the right side to view and download their cv and cover letter.\n\n\n\nDetailed overview over an applicant\n\n\n\n\n4.1.2 Development\nFor development we used React to create the frontend of the website and as language we decided on using TypeScript instead of JavaScript. We used React because it is a very popular frontend framework and also because it is great for creating reusable components. For creating components, we used the Material UI library to get a nice and uniform look through the easy customization of each component provided by Material UI. For navigation, we used the React Router library to create the routes for the different pages.\nRegarding project management for both, frontend and backend, we used GitHub Projects to create a Kanban board to keep track of our tasks and to assign them to different team members. We also used Pull Request to review each others code and to make sure that the code is up to our standards. In our opinion, reviewing each others code is a great way to learn from each other, to learn reading and understanding foreign code and to improve our own coding skills. And as a nice side effect of using GitHub Projects, we were able to keep track of our progress and to make sure, that we are on track with our project.\nFor Routing through the different pages, we used the React Router library to create the routes. We created a API module so that we have a standardize and easy way to fetch data from our backend REST-API. In regards to TypeScript types we defined all types object orientated like we designed them in the backend and used them throughout the project to make sure that we have a consistent type system.\nWhen it comes to creating components, we divided our mockup into smaller parts and created a component for each part. We always tried to create reusable components to make sure that we have a consistent look throughout the website. To ensure that the components don’t become too big, we also created smaller helper components to make sure that the components are easy to understand and to maintain. We also created a theme for the website to make sure that we have a consistent look throughout the website.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "implementation.html#backend",
    "href": "implementation.html#backend",
    "title": "4  Implementation",
    "section": "4.2 Backend",
    "text": "4.2 Backend\n\n4.2.1 Backend Design\nFor designing the backend, we used the Entity Relationship Diagram (ERD) to get a better idea of what we wanted the database to look like and we also used class diagrams to model a raw structure of the backend. In addition to the ERD we figured out, which type of database we should use for what kind of data.\n\n4.2.1.1 Class Diagram\n\n\n\nThe class diagram containing all the classes\n\n\nAs the class diagram shows all classes interhit the business object, so every instance of every class gets a id and a creation date. The class User could be missleading, since the applicant is not a user in the system per se, but still inherits the fistname and the lastname from the user. The Idea was to also create a Employee class, which would inherit from the user, but we did not have the time to implement it. Both the properties department and the wokring_hours are realized with a enum, so that the user can only choose from a predefined set of values. The explanation on how we implemented all the classes can be found in the section Backend Development.\n\n\n4.2.1.2 Entity Relationship Diagram\n\n\n\nEntity Relationship Diagram containing all the tables of the relational database\n\n\nThe Entity Relationship Diagram shows all the tables of our relational database. We added a additional table for the evaluation, just to keep track of how good the rating of the applicant was. Other than that we are not using the data of the evaluation table in the application itself. More information on how we implemented the relational database can be found in the section Backend Development.\nAs mentioned earlier we are using both a relational database and a document database. The reason for that is, that we are also dealing with documents besides the objects, which are shown in the class diagram. Each vacancy pdf, which is uploaded by a user is getting stored inside the document database. This has the advantage, that both storing and retrieval is more efficient with a document database than with a relational database, since we are dealing with larger files. How we implemented the document database is explained in the section Backend Development .\n\n\n\n4.2.2 Backend Development\n\n4.2.2.1 Databases\nFor the relational database we used MySQL and for the document database we used MongoDB. We are using Docker to run both of these Databases inside Docker containers, which are build with the help of a docker-compose file. The reason for that is, that if there are any changes to the database, we can simply delete the container and rebuild it with the new changes. In addition to that we have initial sql scripts, which are executed when the container is build. This is done to make sure, that the database is always in the same state, no matter on which machine it is running. Another important point is, that both databases can be started, stopped, built and destroyed with a single command. This is very convenient, since we do not have to start and stop each databse manually. Both containers are based on the latest images of the databases, so that we always have the latest version of the database. The docker-compose file can be found here.\nFor working with the realtional database we where using either DBeaver or a extension for Visual Studio Code by Weijan Chen. For working with the document database we used MongoDB Compass, or also another Visual studio Code extension, by MongoDB itself, to get a better overview over the documents and to make sure that the documents are stored correctly.\nStoring data inside the mongodb is different than storing data inside a relational database. In a relational database you have tables, which are connected to each other with foreign keys. In a document database you have collections, which are similar to tables, but you do not have foreign keys. In our case we were using GridFS from MongoDB. The reason for that is, in case somebody uploads a large file, which means bigger than 16MB, we can still handle it. The way GridFS works is, that it splits the file into smaller chunks and stores them in a fs.chunks collection. The metadata of the file is stored in the fs.files collection.\n\n\n4.2.2.2 Backend Application\nSince we need a API connection to both GPT-4 and to our frontend, we decided to use Python and Flask. We build an API with different endpoints for our frontend. These different endpoints can be found here. Because of the limited time, we just implemented the CRUD operations we needed. All other operations are specified inside the abstract mapper classes for both databases, so they can be implemented fairly easy. The mapper classes can be found here.\nEach class shown in the class diagramm above implements both getter and setter methods to set and get properties for each instance. The properties are defined as private, so that they can only be accessed by the getter and setter methods. The reason for that is, that we can make sure, that the properties are only set to valid values. All of the classes can be found here. The following list shows the operations where we use the GPT-4 API:\n\nThe extraction of personal data from the CV in function get_personal_data_from_cv inside cv_service.py\nThe creation of categories and their chips (rather tags, but by accident we went with the term for the corresponding UI element instead) in function assign_chip inside category_service.py\nThe creation of the vacancy text in function generate_text inside vacancy_service.py\nThe evaluation inside rating_service.py, which will be explained more in detail in the evaluation section.\n\nAs mentioned in the beginning of this section we have also implemented a connection to the OpenAI GPT-4 API. Those API calls are stored in different services throughtout the project. The services can be found here.\nThe services in general are not only used for API interactions with OpenAI but also for other operations, with different classes. For this reason each class has its own service, which is responsible for the operations of the class.\nWe used multiple different python packages to implement the backend. You can find all packages here inside the requirements file.\nAll functions inside the the backend repository are documented with the help of the autoDocstring extension for Visual Studio Code. This is done to maintain a consistent documentation throughout the project and to make sure that the code is easy to understand for other developers.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "evaluation.html",
    "href": "evaluation.html",
    "title": "5  Evaluation",
    "section": "",
    "text": "Since we are utilizing the large language model in ways where there are no strictly right or wrong answers, we cannot employ the evals framework developed and maintained by OpenAI. Instead, we opted for a distinct method of evaluation. We selected an existing job posting from Meta for a Frontend Developer position and had ChatGPT (GPT-3.5) generate approximately 40 applications, which were then manually evaluated. Subsequently, we utilized GPT-4 to have the same 40 applications evaluated. To facilitate a comparison, we employed the same evaluation categories as those used for the manual assessments. These categories are detailed below, alongside guidelines with examples for scores of 0 and 10 points for each category, to make the evaluation process as impartial as possible:\n\nEducation and Degrees\n\n0: No formal education or relevant degree.\n10: Ph.D. in Computer Science, Engineering, Applied Sciences, Mathematics, Physics, or a related field with an exceptional academic record.\n\nJavaScript/TypeScript Proficiency\n\n0: No knowledge or experience with JavaScript/TypeScript.\n10: Expert in JavaScript/TypeScript, demonstrated by significant contributions to complex front-end systems and extensive experience in architectural design.\n\nHTML & CSS Skills\n\n0: Limited or no understanding of HTML & CSS.\n10: Mastery of HTML & CSS, with the ability to create efficient and visually appealing user interfaces.\n\nFramework Familiarity (e.g., Prototype JS, MooTools, Dojo)\n\n0: No experience with any JavaScript or TypeScript frameworks.\n10: Extensive expertise in multiple Object-Oriented JavaScript Frameworks, such as Prototype JS, MooTools, or Dojo, and a proven ability to architect complex front-end systems.\n\nAutomated Testing for Frontend Code\n\n0: No experience in implementing automated testing for frontend code.\n10: Adept at implementing comprehensive automated testing strategies for front-end code, ensuring high performance and reliability.\n\nCollaboration and Code Reviews\n\n0: Poor collaboration skills and minimal participation in code reviews.\n10: Exceptional collaboration skills, actively contributing to design and code reviews, and effectively incorporating feedback from team members.\n\nTeamwork\n\n0: Works in isolation, lacks teamwork skills.\n10: Outstanding teamwork, demonstrated by effective interaction with product designers, and contributing to the overall improvement of the engineering team’s performance.\n\n\nOur system conducted evaluations using both GPT-3.5-turbo and GPT-4-1106-preview, identifying a discrepancy in the average scores when compared to manual evaluations: a 2.0 gap for GPT-3.5-turbo and a mere 0.7 difference for GPT-4-1106-preview. The evaluation yielded very promising results, indicating that the AI evaluated the applications in the manner we desired without hallucinations. TODO: Trap of averages irgendwie erwähnen, dass wir das natürlich bedacht haben 😇\nA critical step in our evaluation process involves requiring the model to provide a justification and a quote from the CV for each score. These quotes are then verified by a function within our application to confirm their presence in the CV, effectively preventing model hallucinations.\nFurthermore, we implement a new evaluation step wherein the original prompt, along with the model’s response including score quotes and justifications, is sent back to the model as a complete package. The task for the model is to self-assess and evaluate how well its response matches the criteria. This self-assessment is currently only stored in our database and serves as an indicator for developers on the accuracy of the evaluation, whether on a general level or for individual CVs.\nA potential next step could involve introducing a threshold, prompting the model to revise its own response if the self-assessment falls below this value. This mechanism would not only enhance the quality of AI evaluations further but also increase the system’s reliability by introducing an additional layer of verification to ensure the accuracy of the evaluations.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "user_instructions.html",
    "href": "user_instructions.html",
    "title": "6  User Instructions",
    "section": "",
    "text": "6.1 Vacancy Generation",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>User Instructions</span>"
    ]
  },
  {
    "objectID": "user_instructions.html#vacancy-generation",
    "href": "user_instructions.html#vacancy-generation",
    "title": "6  User Instructions",
    "section": "",
    "text": "6.1.1 Step 1: Navigate to Inquiries\n\nGo to the “Inquiries” page on our platform.\nAt the top of the page, find and click the “Create” button.\nScreenshot: \n\n\n\n6.1.2 Step 2: Enter Basic Information\n\nYou will be directed to a page to enter basic vacancy information. Fill in all fields:\n\nJob Title\nDepartment\nTasks and Responsibilities: Brief points are sufficient as AI will enhance this section later.\nWorking Hours\nDescription\n\nScreenshot: \n\n\n\n6.1.3 Step 3: Skill Selection\n\nProceed to “Select Skills” and choose the necessary skills via checkboxes.\nTo add a new skill, click the “New Skill” button and enter the skill name. The category and guidelines will be auto-generated.\nScreenshot: \n\n\n\n6.1.4 Step 4: Assigning Weights to Skills\n\nAfter selecting skills, assign weights to each, crucial for calculating applicant scores.\nUse “Auto Weight” for equal distribution or manually enter percentages and lock them.\nScreenshot: \n\n\n\n6.1.5 Step 5: Final Overview and Vacancy Text Generation\n\nReview all selected information and skills.\nUse “Generate” to create the vacancy text, modifying the prompt if necessary.\nClick “Save” to store the vacancy.\nScreenshot:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>User Instructions</span>"
    ]
  },
  {
    "objectID": "user_instructions.html#uploading-a-new-applicant",
    "href": "user_instructions.html#uploading-a-new-applicant",
    "title": "6  User Instructions",
    "section": "6.2 Uploading a New Applicant",
    "text": "6.2 Uploading a New Applicant\n\n6.2.1 Step 1: Click Upload\n\nClick on “Upload” in the navigation bar.\nSelect the vacancy for which you are uploading the CV.\n\n\n\n6.2.2 Step 2: Upload CV\n\nDrag and drop your CV as a PDF into the designated window.\nClick the “Send” button to upload the applicant.\nScreenshot: \n\n\n\n6.2.3 Step 3: Review Applicant\n\nNavigate to “Vacancies” in the navigation bar and select the relevant vacancy.\nAll applicants for the vacancy will be listed; click on “Details” for the new applicant.\nScreenshot: \n\n\n\n6.2.4 Step 4: Applicant Overview\n\nYou will see a detailed overview of the applicant, including their total score and scores for individual categories.\nJustifications for the scores and quotes from the CV supporting these assessments are provided.\nScreenshot:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>User Instructions</span>"
    ]
  },
  {
    "objectID": "future_road_map.html",
    "href": "future_road_map.html",
    "title": "7  Future Road Map",
    "section": "",
    "text": "7.1 Anonymize the Data\nThe current implementation does not anonymize the data. This means that the AI will have access to the applicant’s personal information. This is a privacy concern and should be addressed. The AI should not have access to the applicant’s personal information. The AI should only have access to the applicant’s CV and the vacancy requirements. The personal information should be anonymized before it is passed to the AI. Also the application should be GDPR compliant.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Future Road Map</span>"
    ]
  },
  {
    "objectID": "future_road_map.html#manual-score-adjustment",
    "href": "future_road_map.html#manual-score-adjustment",
    "title": "7  Future Road Map",
    "section": "7.2 Manual Score Adjustment",
    "text": "7.2 Manual Score Adjustment\nThe current implementation lets the AI rate the applicants CV and based on the vacancy requirements. However, it would be a good idea to let the HR manager adjust the score manually. This way, the HR manager can adjust the score if they feel that the AI has rated the CV incorrectly or after an interview, they can adjust the score based on the interview.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Future Road Map</span>"
    ]
  },
  {
    "objectID": "future_road_map.html#interview-preparation",
    "href": "future_road_map.html#interview-preparation",
    "title": "7  Future Road Map",
    "section": "7.3 Interview Preparation",
    "text": "7.3 Interview Preparation\nThe current implementation does not include any interview preparation. It would be a good idea to include a feature that would help the HR manager to prepare for the interview. This could include a list of questions that the HR manager can ask the applicant based on the CV and the vacancy requirements. If the vacancy is for a developer, the system could suggest a list of technical questions that the HR manager can ask the applicant or suggest a case study that the HR manager can use to test the applicant’s skills.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Future Road Map</span>"
    ]
  },
  {
    "objectID": "future_road_map.html#processing-of-cover-letters",
    "href": "future_road_map.html#processing-of-cover-letters",
    "title": "7  Future Road Map",
    "section": "7.4 Processing of cover letters",
    "text": "7.4 Processing of cover letters\nThe application currently only processes the CV. However, it would be nice to include a feature that would process the cover letter as well. The cover letter is an important part of the application and can provide valuable information about the applicant. The system should be able to process the cover letter and extract the information from it.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Future Road Map</span>"
    ]
  },
  {
    "objectID": "future_road_map.html#processing-different-cv-formats",
    "href": "future_road_map.html#processing-different-cv-formats",
    "title": "7  Future Road Map",
    "section": "7.5 Processing different CV formats",
    "text": "7.5 Processing different CV formats\nSometimes CVs are in different formats. In some templates, skills are visualized as a slider, in others as a bar or a pie chart. The system should be able to process different CV formats and extract the information from them. The following are some examples of different CV formats:\n\n\n\nLanguage Skills as slider element\n\n\n\n\n\nLanguage Skills as dots\n\n\n\n\n\nPersonality Description with bars",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Future Road Map</span>"
    ]
  },
  {
    "objectID": "future_road_map.html#automatic-upload-of-cvs",
    "href": "future_road_map.html#automatic-upload-of-cvs",
    "title": "7  Future Road Map",
    "section": "7.6 Automatic Upload of CVs",
    "text": "7.6 Automatic Upload of CVs\nGenerally, the idea was to create an application where an applicant would be able to upload their CV. However, the current implementation does not include this feature. The HR manager has to manually upload the CV. It would be a good idea to either include a feature that would allow the applicant to upload their CV directly to the system or to implement a feature that would automatically upload the CV from the company’s email or from a job portal.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Future Road Map</span>"
    ]
  },
  {
    "objectID": "future_road_map.html#integration-with-datev",
    "href": "future_road_map.html#integration-with-datev",
    "title": "7  Future Road Map",
    "section": "7.7 Integration with DATEV",
    "text": "7.7 Integration with DATEV\nDuring the development wo received feedback from a recruiter that it would be helpful to have an integration with DATEV. DATEV is used by many companies in Germany for accounting and HR management. It would be beneficial to have an integration with DATEV so that the HR manager can easily import the applicant’s information into DATEV. This would save the HR manager time and reduce the risk of errors when entering the applicant’s information into DATEV manually.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Future Road Map</span>"
    ]
  }
]